{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc98d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gaby\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\gaby\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gaby\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six in c:\\users\\gaby\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2423281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / c++ / python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu ram sedangkan yang di prioritaskan akan langsung di proses oleh cpu.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. Perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / C++ / Python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu RAM sedangkan yang di prioritaskan akan langsung di proses oleh CPU.\"\n",
    "\n",
    "# gunakan fungsi .lower()\n",
    "lowercase_sentence = sentence.lower()\n",
    "\n",
    "print(lowercase_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2a4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / c++ / python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu ram sedangkan yang di prioritaskan akan langsung di proses oleh cpu.\n",
      "n\n",
      "\n",
      "\n",
      "Tokenizing Result : \n",
      "\n",
      "['saya', 'mempelajari', 'cara', 'kerja', 'perintah', 'yang', 'masuk', 'kedalam', 'komputer', 'lalu', 'cara', 'memproses', 'perintah', 'tersebut', 'dan', 'yang', 'dihasilkan', 'dari', 'perintah', 'terebut', 'perintah', 'tidak', 'akan', 'langsung', 'dieksekusi', 'masih', 'ada', 'delay', 'seperti', 'urutan', 'perintah', 'pada', 'video', 'dijelasakan', 'perintah', 'masuk', 'akan', 'dideteksi', 'dan', 'di', 'masukkan', 'dalam', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'perintah', 'yang', 'delay', 'tersebut', 'akan', 'dikirim', 'pada', 'penyimpanan', 'sementara', 'yaitu', 'ram', 'sedangkan', 'yang', 'di', 'prioritaskan', 'akan', 'langsung', 'di', 'proses', 'oleh', 'cpu']\n",
      "Frequency Tokens : \n",
      "\n",
      "[('perintah', 7), ('yang', 4), ('akan', 4), ('di', 3), ('cara', 2), ('masuk', 2), ('tersebut', 2), ('dan', 2), ('langsung', 2), ('delay', 2), ('pada', 2), ('saya', 1), ('mempelajari', 1), ('kerja', 1), ('kedalam', 1), ('komputer', 1), ('lalu', 1), ('memproses', 1), ('dihasilkan', 1), ('dari', 1), ('terebut', 1), ('tidak', 1), ('dieksekusi', 1), ('masih', 1), ('ada', 1), ('seperti', 1), ('urutan', 1), ('video', 1), ('dijelasakan', 1), ('dideteksi', 1), ('masukkan', 1), ('dalam', 1), ('pengelompokan', 1), ('bahasa', 1), ('java', 1), ('c', 1), ('python', 1), ('dikirim', 1), ('penyimpanan', 1), ('sementara', 1), ('yaitu', 1), ('ram', 1), ('sedangkan', 1), ('prioritaskan', 1), ('proses', 1), ('oleh', 1), ('cpu', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\GABY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re #regex library\n",
    "\n",
    "# import word_tokenize from NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Case Folding\n",
    "# gunakan fungsi .lower()\n",
    "lowercase_sentence = sentence.lower()\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(lowercase_sentence)\n",
    "print('n\\n\\n')\n",
    "\n",
    "#Tokenizing\n",
    "#remove angka\n",
    "lowercase_sentence = re.sub(r\"\\d+\", \"\", lowercase_sentence)\n",
    "\n",
    "#remove punctuation\n",
    "lowercase_sentence = lowercase_sentence.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "#remove whitespace Leading & Trailing\n",
    "lowercase_sentence = re.sub('\\s+', ' ', lowercase_sentence)\n",
    "\n",
    "tokens = nltk.tokenize.word_tokenize(lowercase_sentence)\n",
    "\n",
    "print('Tokenizing Result : \\n')\n",
    "print(tokens)\n",
    "freq_tokens = nltk.FreqDist(tokens)\n",
    "\n",
    "print('Frequency Tokens : \\n')\n",
    "print(freq_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dab7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : \n",
      "\n",
      "['perintah', 'masuk', 'langsung', 'delay', 'mempelajari', 'kerja', 'kedalam', 'komputer', 'memproses', 'dihasilkan', 'terebut', 'dieksekusi', 'urutan', 'video', 'dijelasakan', 'dideteksi', 'masukkan', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'dikirim', 'penyimpanan', 'ram', 'prioritaskan', 'proses', 'cpu']\n",
      "Tokenizing Result : \n",
      "\n",
      "['perintah', 'masuk', 'langsung', 'delay', 'mempelajari', 'kerja', 'kedalam', 'komputer', 'memproses', 'dihasilkan', 'terebut', 'dieksekusi', 'urutan', 'video', 'dijelasakan', 'dideteksi', 'masukkan', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'dikirim', 'penyimpanan', 'ram', 'prioritaskan', 'proses', 'cpu']\n",
      "Frequency Tokens : \n",
      "\n",
      "[('perintah', 1), ('masuk', 1), ('langsung', 1), ('delay', 1), ('mempelajari', 1), ('kerja', 1), ('kedalam', 1), ('komputer', 1), ('memproses', 1), ('dihasilkan', 1), ('terebut', 1), ('dieksekusi', 1), ('urutan', 1), ('video', 1), ('dijelasakan', 1), ('dideteksi', 1), ('masukkan', 1), ('pengelompokan', 1), ('bahasa', 1), ('java', 1), ('c', 1), ('python', 1), ('dikirim', 1), ('penyimpanan', 1), ('ram', 1), ('prioritaskan', 1), ('proses', 1), ('cpu', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GABY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# tokenize text\n",
    "freq_tokens\n",
    "\n",
    "# get Indonesian stopword \n",
    "list_stopwords = set(stopwords.words('indonesian'))\n",
    "\n",
    "#remove stopword pada list token\n",
    "tokens_without_stopword = [word for word in freq_tokens if not word in list_stopwords]\n",
    "\n",
    "print('Stopwords : \\n')\n",
    "print(tokens_without_stopword)\n",
    "\n",
    "print('Tokenizing Result : \\n')\n",
    "print(tokens)\n",
    "freq_tokens = nltk.FreqDist(tokens)\n",
    "\n",
    "print('Frequency Tokens : \\n')\n",
    "print(freq_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf32080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0d325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
