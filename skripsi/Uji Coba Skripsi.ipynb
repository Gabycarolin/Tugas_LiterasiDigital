{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2423281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / c++ / python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu ram sedangkan yang di prioritaskan akan langsung di proses oleh cpu.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. Perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / C++ / Python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu RAM sedangkan yang di prioritaskan akan langsung di proses oleh CPU.\"\n",
    "\n",
    "# gunakan fungsi .lower()\n",
    "lowercase_sentence = sentence.lower()\n",
    "\n",
    "print(lowercase_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2a4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\GABY\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "saya mempelajari cara kerja perintah yang masuk kedalam komputer lalu cara memproses perintah tersebut dan yang dihasilkan dari perintah terebut. perintah tidak akan langsung dieksekusi masih ada delay seperti urutan perintah, pada video dijelasakan perintah masuk akan dideteksi dan di masukkan dalam pengelompokan bahasa java / c++ / python, perintah yang delay tersebut akan dikirim pada penyimpanan sementara yaitu ram sedangkan yang di prioritaskan akan langsung di proses oleh cpu.\n",
      "n\n",
      "\n",
      "\n",
      "Tokenizing Result : \n",
      "\n",
      "['saya', 'mempelajari', 'cara', 'kerja', 'perintah', 'yang', 'masuk', 'kedalam', 'komputer', 'lalu', 'cara', 'memproses', 'perintah', 'tersebut', 'dan', 'yang', 'dihasilkan', 'dari', 'perintah', 'terebut', 'perintah', 'tidak', 'akan', 'langsung', 'dieksekusi', 'masih', 'ada', 'delay', 'seperti', 'urutan', 'perintah', 'pada', 'video', 'dijelasakan', 'perintah', 'masuk', 'akan', 'dideteksi', 'dan', 'di', 'masukkan', 'dalam', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'perintah', 'yang', 'delay', 'tersebut', 'akan', 'dikirim', 'pada', 'penyimpanan', 'sementara', 'yaitu', 'ram', 'sedangkan', 'yang', 'di', 'prioritaskan', 'akan', 'langsung', 'di', 'proses', 'oleh', 'cpu']\n",
      "Frequency Tokens : \n",
      "\n",
      "[('perintah', 7), ('yang', 4), ('akan', 4), ('di', 3), ('cara', 2), ('masuk', 2), ('tersebut', 2), ('dan', 2), ('langsung', 2), ('delay', 2), ('pada', 2), ('saya', 1), ('mempelajari', 1), ('kerja', 1), ('kedalam', 1), ('komputer', 1), ('lalu', 1), ('memproses', 1), ('dihasilkan', 1), ('dari', 1), ('terebut', 1), ('tidak', 1), ('dieksekusi', 1), ('masih', 1), ('ada', 1), ('seperti', 1), ('urutan', 1), ('video', 1), ('dijelasakan', 1), ('dideteksi', 1), ('masukkan', 1), ('dalam', 1), ('pengelompokan', 1), ('bahasa', 1), ('java', 1), ('c', 1), ('python', 1), ('dikirim', 1), ('penyimpanan', 1), ('sementara', 1), ('yaitu', 1), ('ram', 1), ('sedangkan', 1), ('prioritaskan', 1), ('proses', 1), ('oleh', 1), ('cpu', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re #regex library\n",
    "\n",
    "# import word_tokenize from NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Case Folding\n",
    "# gunakan fungsi .lower()\n",
    "lowercase_sentence = sentence.lower()\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(lowercase_sentence)\n",
    "print('n\\n\\n')\n",
    "\n",
    "#Tokenizing\n",
    "#remove angka\n",
    "lowercase_sentence = re.sub(r\"\\d+\", \"\", lowercase_sentence)\n",
    "\n",
    "#remove punctuation\n",
    "lowercase_sentence = lowercase_sentence.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "#remove whitespace Leading & Trailing\n",
    "lowercase_sentence = re.sub('\\s+', ' ', lowercase_sentence)\n",
    "\n",
    "tokens = nltk.tokenize.word_tokenize(lowercase_sentence)\n",
    "\n",
    "print('Tokenizing Result : \\n')\n",
    "print(tokens)\n",
    "freq_tokens = nltk.FreqDist(tokens)\n",
    "\n",
    "print('Frequency Tokens : \\n')\n",
    "print(freq_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dab7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords : \n",
      "\n",
      "['perintah', 'masuk', 'langsung', 'delay', 'mempelajari', 'kerja', 'kedalam', 'komputer', 'memproses', 'dihasilkan', 'terebut', 'dieksekusi', 'urutan', 'video', 'dijelasakan', 'dideteksi', 'masukkan', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'dikirim', 'penyimpanan', 'ram', 'prioritaskan', 'proses', 'cpu']\n",
      "Tokenizing Result : \n",
      "\n",
      "['saya', 'mempelajari', 'cara', 'kerja', 'perintah', 'yang', 'masuk', 'kedalam', 'komputer', 'lalu', 'cara', 'memproses', 'perintah', 'tersebut', 'dan', 'yang', 'dihasilkan', 'dari', 'perintah', 'terebut', 'perintah', 'tidak', 'akan', 'langsung', 'dieksekusi', 'masih', 'ada', 'delay', 'seperti', 'urutan', 'perintah', 'pada', 'video', 'dijelasakan', 'perintah', 'masuk', 'akan', 'dideteksi', 'dan', 'di', 'masukkan', 'dalam', 'pengelompokan', 'bahasa', 'java', 'c', 'python', 'perintah', 'yang', 'delay', 'tersebut', 'akan', 'dikirim', 'pada', 'penyimpanan', 'sementara', 'yaitu', 'ram', 'sedangkan', 'yang', 'di', 'prioritaskan', 'akan', 'langsung', 'di', 'proses', 'oleh', 'cpu']\n",
      "Frequency Tokens : \n",
      "\n",
      "[('perintah', 7), ('yang', 4), ('akan', 4), ('di', 3), ('cara', 2), ('masuk', 2), ('tersebut', 2), ('dan', 2), ('langsung', 2), ('delay', 2), ('pada', 2), ('saya', 1), ('mempelajari', 1), ('kerja', 1), ('kedalam', 1), ('komputer', 1), ('lalu', 1), ('memproses', 1), ('dihasilkan', 1), ('dari', 1), ('terebut', 1), ('tidak', 1), ('dieksekusi', 1), ('masih', 1), ('ada', 1), ('seperti', 1), ('urutan', 1), ('video', 1), ('dijelasakan', 1), ('dideteksi', 1), ('masukkan', 1), ('dalam', 1), ('pengelompokan', 1), ('bahasa', 1), ('java', 1), ('c', 1), ('python', 1), ('dikirim', 1), ('penyimpanan', 1), ('sementara', 1), ('yaitu', 1), ('ram', 1), ('sedangkan', 1), ('prioritaskan', 1), ('proses', 1), ('oleh', 1), ('cpu', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GABY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# tokenize text \n",
    "# freq_tokens \n",
    "\n",
    "# get Indonesian stopword \n",
    "list_stopwords = set(stopwords.words('indonesian')) \n",
    "\n",
    "#remove stopword pada list token \n",
    "tokens_without_stopword = [word for word in freq_tokens if not word in list_stopwords] \n",
    "\n",
    "print('Stopwords : \\n') \n",
    "print(tokens_without_stopword) \n",
    "print('Tokenizing Result : \\n') \n",
    "\n",
    "print(tokens) \n",
    "freq_tokens = nltk.FreqDist(tokens) \n",
    "\n",
    "print('Frequency Tokens : \\n') \n",
    "print(freq_tokens.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf32080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbe3f9-96fb-4195-a1f5-4e6f8e8bb0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878751f-a618-4dbe-ab23-7e8fd1e52220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0022fb0-f25c-4676-a940-801fb63a2def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
